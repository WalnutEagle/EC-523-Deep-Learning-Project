{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 106/106 [07:42<00:00,  4.36s/batch, loss=0.000626]\n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 106/106 [07:33<00:00,  4.28s/batch, loss=0.000442]\n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 106/106 [07:32<00:00,  4.27s/batch, loss=0.000128]\n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 106/106 [07:32<00:00,  4.27s/batch, loss=0.000104]\n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 106/106 [07:32<00:00,  4.26s/batch, loss=7.15e-5]\n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 106/106 [07:32<00:00,  4.27s/batch, loss=0.000176]\n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 106/106 [07:31<00:00,  4.26s/batch, loss=4.42e-5]\n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 106/106 [07:32<00:00,  4.27s/batch, loss=5.8e-5] \n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 106/106 [07:33<00:00,  4.28s/batch, loss=0.000138]\n",
      "  0%|          | 0/106 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 106/106 [07:32<00:00,  4.27s/batch, loss=0.000121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0110\n",
      "Training finished.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c1b40ab48b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"generator_{BATCH_SIZE}_{IMAGE_SIZE}_epoch_{EPOCHS}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"discriminator_{BATCH_SIZE}_{IMAGE_SIZE}_epoch_{EPOCHS}.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Models saved at epoch {EPOCHS} with batch size {BATCH_SIZE} and image size {IMAGE_SIZE}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset Class\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_folder, transform=None):\n",
    "        self.csv = pd.read_csv(csv_file)\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "        self.pairs = self.csv.groupby('uid')  \n",
    "        self.valid_uids = self.check_integrity()\n",
    "\n",
    "    def check_integrity(self):\n",
    "        valid_uids = []\n",
    "        for uid, group in self.pairs:\n",
    "            frontal_data = group[group['projection'] == 'Frontal']\n",
    "            lateral_data = group[group['projection'] == 'Lateral']\n",
    "            if frontal_data.empty or lateral_data.empty:\n",
    "                continue\n",
    "            valid_uids.append(uid)\n",
    "        return valid_uids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_uids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        group_key = self.valid_uids[idx]\n",
    "        uid = self.pairs.get_group(group_key)\n",
    "\n",
    "        frontal_img_path = os.path.join(self.img_folder, uid[uid['projection'] == 'Frontal']['filename'].values[0])\n",
    "        lateral_img_path = os.path.join(self.img_folder, uid[uid['projection'] == 'Lateral']['filename'].values[0])\n",
    "        frontal_img = Image.open(frontal_img_path).convert(\"RGB\")\n",
    "        lateral_img = Image.open(lateral_img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            frontal_img = self.transform(frontal_img)\n",
    "            lateral_img = self.transform(lateral_img)\n",
    "\n",
    "        return frontal_img, lateral_img\n",
    "\n",
    "# Define the Dense Block\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels + i * growth_rate, growth_rate, kernel_size=3, padding=1),\n",
    "                nn.InstanceNorm2d(growth_rate),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            new_features = layer(x)\n",
    "            x = torch.cat([x, new_features], dim=1)\n",
    "        return x\n",
    "\n",
    "# Define the Basic3D Block\n",
    "class Basic3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Basic3D, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "# Define 2D to 3D Connection (Connection-C)\n",
    "class Connection2Dto3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Connection2Dto3D, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3d = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = x.unsqueeze(2)\n",
    "        x = self.conv3d(x)\n",
    "        return x\n",
    "\n",
    "# Define Generator Architecture\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_dense_layers, out_channels, image_size):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.num_upconv_layers = int(torch.log2(torch.tensor(image_size // 4)).item())\n",
    "\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n",
    "            DenseBlock(growth_rate, growth_rate, num_dense_layers),\n",
    "            nn.Conv2d(growth_rate * (num_dense_layers + 1), growth_rate, kernel_size=3, stride=2, padding=1)  # Compression\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n",
    "            DenseBlock(growth_rate, growth_rate, num_dense_layers),\n",
    "            nn.Conv2d(growth_rate * (num_dense_layers + 1), growth_rate, kernel_size=3, stride=2, padding=1)  # Compression\n",
    "        )\n",
    "\n",
    "        self.connection_a = Connection2Dto3D(growth_rate, growth_rate)\n",
    "        self.connection_b = nn.Conv3d(growth_rate * 2, growth_rate, kernel_size=3, padding=1)\n",
    "        self.connection_c = nn.Conv3d(growth_rate, growth_rate, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv_layers = nn.ModuleList()\n",
    "        for _ in range(self.num_upconv_layers):\n",
    "            self.upconv_layers.append(nn.Sequential(\n",
    "                nn.ConvTranspose3d(growth_rate, growth_rate, kernel_size=4, stride=2, padding=1),\n",
    "                nn.InstanceNorm3d(growth_rate),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "\n",
    "        self.final_layer = nn.Conv3d(growth_rate, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.encoder1(x1)\n",
    "        x2 = self.encoder2(x2)\n",
    "        x1 = self.connection_a(x1)\n",
    "        x2 = self.connection_a(x2)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.connection_b(x)\n",
    "        for upconv in self.upconv_layers:\n",
    "            x = upconv(x)\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "\n",
    "# Training logic\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    IMAGE_FOLDER = '/projectnb/ec523kb/projects/teams_Fall_2024/Team_11/Adwait/Work_on_this_code/images/images_normalized/'\n",
    "    CSV_FILE = '/projectnb/ec523kb/projects/teams_Fall_2024/Team_11/Adwait/Work_on_this_code/indiana_projections.csv'\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 10\n",
    "    IMAGE_SIZE = 100\n",
    "    LATENT_DIM = 1000\n",
    "    IN_CHANNELS = 3\n",
    "    OUT_CHANNELS = 1\n",
    "    GROWTH_RATE = 16\n",
    "    NUM_DENSE_LAYERS = 4\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "    dataset = XRayDataset(CSV_FILE, IMAGE_FOLDER, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generator = Generator(\n",
    "        in_channels=IN_CHANNELS,\n",
    "        growth_rate=GROWTH_RATE,\n",
    "        num_dense_layers=NUM_DENSE_LAYERS,\n",
    "        out_channels=OUT_CHANNELS,\n",
    "        image_size=IMAGE_SIZE\n",
    "    )\n",
    "    generator = nn.DataParallel(generator)  # Enable multi-GPU\n",
    "    generator = generator.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        generator.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "            for frontal_img, lateral_img in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "                frontal_img = frontal_img.to(device)\n",
    "                lateral_img = lateral_img.to(device)\n",
    "\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = generator(frontal_img, lateral_img)\n",
    "                loss = criterion(output, torch.zeros_like(output).to(device))\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}\")\n",
    "    print(\"Training finished.\")\n",
    "    torch.save(generator.state_dict(), f\"generator_{BATCH_SIZE}_{IMAGE_SIZE}_epoch_{EPOCHS}.pth\")\n",
    "#     torch.save(discriminator.state_dict(), f\"discriminator_{BATCH_SIZE}_{IMAGE_SIZE}_epoch_{EPOCHS}.pth\")\n",
    "\n",
    "    print(f\"Models saved at epoch {EPOCHS} with batch size {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Dataset Class\n",
    "# class XRayDataset(Dataset):\n",
    "#     def __init__(self, csv_file, img_folder, transform=None):\n",
    "#         self.csv = pd.read_csv(csv_file)\n",
    "#         self.img_folder = img_folder\n",
    "#         self.transform = transform\n",
    "#         self.pairs = self.csv.groupby('uid')  # Group by UID\n",
    "#         self.valid_uids = self.check_integrity()  # Ensure dataset integrity\n",
    "\n",
    "#     def check_integrity(self):\n",
    "#         valid_uids = []\n",
    "#         for uid, group in self.pairs:\n",
    "#             frontal_data = group[group['projection'] == 'Frontal']\n",
    "#             lateral_data = group[group['projection'] == 'Lateral']\n",
    "#             if frontal_data.empty or lateral_data.empty:\n",
    "#                 continue\n",
    "#             valid_uids.append(uid)\n",
    "#         return valid_uids\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.valid_uids)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         group_key = self.valid_uids[idx]\n",
    "#         uid = self.pairs.get_group(group_key)\n",
    "\n",
    "#         # Find the paths for the frontal and lateral images\n",
    "#         frontal_img_path = os.path.join(self.img_folder, uid[uid['projection'] == 'Frontal']['filename'].values[0])\n",
    "#         lateral_img_path = os.path.join(self.img_folder, uid[uid['projection'] == 'Lateral']['filename'].values[0])\n",
    "\n",
    "#         # Load images\n",
    "#         frontal_img = Image.open(frontal_img_path).convert(\"RGB\")\n",
    "#         lateral_img = Image.open(lateral_img_path).convert(\"RGB\")\n",
    "\n",
    "#         if self.transform:\n",
    "#             frontal_img = self.transform(frontal_img)\n",
    "#             lateral_img = self.transform(lateral_img)\n",
    "\n",
    "#         return frontal_img, lateral_img\n",
    "\n",
    "# # Define the Dense Block\n",
    "# class DenseBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, growth_rate, num_layers):\n",
    "#         super(DenseBlock, self).__init__()\n",
    "#         self.layers = nn.ModuleList()\n",
    "#         for i in range(num_layers):\n",
    "#             self.layers.append(nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels + i * growth_rate, growth_rate, kernel_size=3, padding=1),\n",
    "#                 nn.InstanceNorm2d(growth_rate),\n",
    "#                 nn.ReLU(inplace=True)\n",
    "#             ))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         for layer in self.layers:\n",
    "#             new_features = layer(x)\n",
    "#             x = torch.cat([x, new_features], dim=1)\n",
    "#         return x\n",
    "\n",
    "# # Define the Basic3D Block\n",
    "# class Basic3D(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(Basic3D, self).__init__()\n",
    "#         self.block = nn.Sequential(\n",
    "#             nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.InstanceNorm3d(out_channels),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.block(x)\n",
    "\n",
    "# # Define 2D to 3D Connection (Connection-C)\n",
    "# class Connection2Dto3D(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(Connection2Dto3D, self).__init__()\n",
    "#         self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "#         self.conv3d = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv2d(x)\n",
    "#         x = x.unsqueeze(2)  # Add depth dimension\n",
    "#         x = self.conv3d(x)\n",
    "#         return x\n",
    "\n",
    "# # Define Generator Architecture\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, in_channels, growth_rate, num_dense_layers, out_channels, image_size):\n",
    "#         super(Generator, self).__init__()\n",
    "\n",
    "#         # Calculate depth of up-convolutions based on image size\n",
    "#         self.num_upconv_layers = int(torch.log2(torch.tensor(image_size // 4)).item())\n",
    "\n",
    "#         # Encoder: 2D Branches\n",
    "#         self.encoder1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n",
    "#             DenseBlock(growth_rate, growth_rate, num_dense_layers),\n",
    "#             nn.Conv2d(growth_rate * (num_dense_layers + 1), growth_rate, kernel_size=3, stride=2, padding=1)  # Compression\n",
    "#         )\n",
    "\n",
    "#         self.encoder2 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n",
    "#             DenseBlock(growth_rate, growth_rate, num_dense_layers),\n",
    "#             nn.Conv2d(growth_rate * (num_dense_layers + 1), growth_rate, kernel_size=3, stride=2, padding=1)  # Compression\n",
    "#         )\n",
    "\n",
    "#         # Connection Layers\n",
    "#         self.connection_a = Connection2Dto3D(growth_rate, growth_rate)\n",
    "#         self.connection_b = nn.Conv3d(growth_rate * 2, growth_rate, kernel_size=3, padding=1)\n",
    "#         self.connection_c = nn.Conv3d(growth_rate, growth_rate, kernel_size=3, padding=1)\n",
    "\n",
    "#         # Decoder: 3D Branch\n",
    "#         self.upconv_layers = nn.ModuleList()\n",
    "#         for _ in range(self.num_upconv_layers):  # Dynamically add up-conv layers\n",
    "#             self.upconv_layers.append(nn.Sequential(\n",
    "#                 nn.ConvTranspose3d(growth_rate, growth_rate, kernel_size=4, stride=2, padding=1),\n",
    "#                 nn.InstanceNorm3d(growth_rate),\n",
    "#                 nn.ReLU(inplace=True)\n",
    "#             ))\n",
    "\n",
    "#         self.final_layer = nn.Conv3d(growth_rate, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         # Encode both inputs\n",
    "#         x1 = self.encoder1(x1)\n",
    "#         x2 = self.encoder2(x2)\n",
    "\n",
    "#         # Combine with Connection-A\n",
    "#         x1 = self.connection_a(x1)\n",
    "#         x2 = self.connection_a(x2)\n",
    "#         x = torch.cat([x1, x2], dim=1)  # Connection-B\n",
    "\n",
    "#         # Pass through Connection-B\n",
    "#         x = self.connection_b(x)\n",
    "\n",
    "#         # Pass through up-convolutions (Decoder)\n",
    "#         for upconv in self.upconv_layers:\n",
    "#             x = upconv(x)\n",
    "\n",
    "#         # Final 3D output\n",
    "#         x = self.final_layer(x)\n",
    "#         return x\n",
    "    \n",
    "    \n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self, in_channels, growth_rate, num_dense_layers):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.initial_conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n",
    "#             nn.LeakyReLU(0.2, inplace=True)\n",
    "#         )\n",
    "#         self.dense_block = DenseBlock(growth_rate, growth_rate, num_dense_layers)\n",
    "#         self.final_conv = nn.Sequential(\n",
    "#             nn.Conv2d(growth_rate * (num_dense_layers + 1), 1, kernel_size=3, padding=1),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.initial_conv(x)\n",
    "#         x = self.dense_block(x)\n",
    "#         x = self.final_conv(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# # Training logic\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     IMAGE_FOLDER = '/projectnb/ec523kb/projects/teams_Fall_2024/Team_11/Adwait/Work_on_this_code/images/images_normalized/'\n",
    "#     CSV_FILE = '/projectnb/ec523kb/projects/teams_Fall_2024/Team_11/Adwait/Work_on_this_code/indiana_projections.csv'\n",
    "#     BATCH_SIZE = 16\n",
    "#     EPOCHS = 10\n",
    "#     IMAGE_SIZE = 64\n",
    "#     LATENT_DIM = 100\n",
    "#     IN_CHANNELS = 3\n",
    "#     OUT_CHANNELS = 1\n",
    "#     GROWTH_RATE = 16\n",
    "#     NUM_DENSE_LAYERS = 4\n",
    "\n",
    "#     # Define transforms\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "#         transforms.ToTensor()\n",
    "#     ])\n",
    "\n",
    "#     # Dataset and Dataloader\n",
    "#     dataset = XRayDataset(CSV_FILE, IMAGE_FOLDER, transform)\n",
    "#     dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     generator = Generator(\n",
    "#         in_channels=IN_CHANNELS,\n",
    "#         growth_rate=GROWTH_RATE,\n",
    "#         num_dense_layers=NUM_DENSE_LAYERS,\n",
    "#         out_channels=OUT_CHANNELS,\n",
    "#         image_size=IMAGE_SIZE\n",
    "#     )\n",
    "#     generator = nn.DataParallel(generator)  # Enable multi-GPU\n",
    "#     generator = generator.to(device)\n",
    "\n",
    "#     adversarial_loss = nn.BCELoss()\n",
    "\n",
    "#     discriminator = Discriminator(\n",
    "#         in_channels=IN_CHANNELS,\n",
    "#         growth_rate=GROWTH_RATE,\n",
    "#         num_dense_layers=NUM_DENSE_LAYERS\n",
    "#     ).to(device)\n",
    "#     discriminator = nn.DataParallel(discriminator)  # Multi-GPU\n",
    "\n",
    "#     optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "#     optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "#     for epoch in range(EPOCHS):\n",
    "#         generator.train()\n",
    "#         discriminator.train()\n",
    "#         g_loss_epoch = 0\n",
    "#         d_loss_epoch = 0\n",
    "\n",
    "#         with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "#             for frontal_img, lateral_img in tepoch:\n",
    "#                 tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "#                 frontal_img = frontal_img.to(device)\n",
    "#                 lateral_img = lateral_img.to(device)\n",
    "\n",
    "#                 # Generate fake 2D slices\n",
    "#                 fake_slices = generator(frontal_img, lateral_img)\n",
    "\n",
    "#                 # Prepare real 2D slices (placeholder target for now)\n",
    "#                 real_slices = torch.zeros_like(fake_slices).to(device)  # Replace with real target\n",
    "\n",
    "#                 # Adversarial ground truths\n",
    "#                 real_labels = torch.ones(fake_slices.size(0), 1, 1, 1).to(device)\n",
    "#                 fake_labels = torch.zeros(fake_slices.size(0), 1, 1, 1).to(device)\n",
    "\n",
    "#                 # ---------------------\n",
    "#                 #  Train Discriminator\n",
    "#                 # ---------------------\n",
    "#                 optimizer_D.zero_grad()\n",
    "\n",
    "#                 # Real loss\n",
    "#                 real_loss = adversarial_loss(discriminator(real_slices), real_labels)\n",
    "\n",
    "#                 # Fake loss\n",
    "#                 fake_loss = adversarial_loss(discriminator(fake_slices.detach()), fake_labels)\n",
    "\n",
    "#                 # Total loss\n",
    "#                 d_loss = (real_loss + fake_loss) / 2\n",
    "#                 d_loss.backward()\n",
    "#                 optimizer_D.step()\n",
    "\n",
    "#                 # -----------------\n",
    "#                 #  Train Generator\n",
    "#                 # -----------------\n",
    "#                 optimizer_G.zero_grad()\n",
    "\n",
    "#                 # Generator loss (adversarial loss)\n",
    "#                 g_loss = adversarial_loss(discriminator(fake_slices), real_labels)\n",
    "#                 g_loss.backward()\n",
    "#                 optimizer_G.step()\n",
    "\n",
    "#                 # Log losses\n",
    "#                 d_loss_epoch += d_loss.item()\n",
    "#                 g_loss_epoch += g_loss.item()\n",
    "#                 tepoch.set_postfix(g_loss=g_loss.item(), d_loss=d_loss.item())\n",
    "\n",
    "#         print(f\"Epoch {epoch + 1}, G Loss: {g_loss_epoch:.4f}, D Loss: {d_loss_epoch:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
