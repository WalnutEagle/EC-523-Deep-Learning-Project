{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/283 [00:31<49:30, 10.61s/batch, D_Fake_Loss=2.17, D_Real_Loss=2.9, D_loss=5.07, G_loss=3.39]      \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-663e972a337a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0moptimizer_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0md_real_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0md_fake_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fake_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Folder containing your images\n",
    "IMAGE_FOLDER = '/projectnb/ec523kb/projects/teams_Fall_2024/Team_11/Adwait/Work_on_this_code/images/images_normalized/'\n",
    "\n",
    "# CSV file path\n",
    "CSV_FILE = '/projectnb/ec523kb/projects/teams_Fall_2024/Team_11/Adwait/Work_on_this_code/indiana_projections.csv'\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "LATENT_DIM = 512\n",
    "LEARNING_RATE = 0.0002\n",
    "IMAGE_SIZE = 1440 # Reduced image size for 3D reconstruction\n",
    "\n",
    "d_real_losses = []\n",
    "d_fake_losses = []\n",
    "g_losses = []\n",
    "\n",
    "\n",
    "# Define device (cuda if available, otherwise cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset class remains the same\n",
    "# Define dataset class\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_folder, transform=None):\n",
    "        self.csv = pd.read_csv(csv_file)\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "        self.pairs = self.csv.groupby('uid')  # Group by UID\n",
    "        self.valid_uids = self.check_integrity()  # Ensure the integrity of the dataset\n",
    "\n",
    "    def check_integrity(self):\n",
    "        valid_uids = []\n",
    "        for uid, group in self.pairs:\n",
    "            frontal_data = group[group['projection'] == 'Frontal']\n",
    "            lateral_data = group[group['projection'] == 'Lateral']\n",
    "            if frontal_data.empty or lateral_data.empty:\n",
    "                continue\n",
    "            valid_uids.append(uid)\n",
    "        return valid_uids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_uids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        group_key = self.valid_uids[idx]\n",
    "        uid = self.pairs.get_group(group_key)\n",
    "\n",
    "        # Find the paths for the frontal and lateral images\n",
    "        frontal_img_path = os.path.join(self.img_folder, uid[uid['projection'] == 'Frontal']['filename'].values[0])\n",
    "        lateral_img_path = os.path.join(self.img_folder, uid[uid['projection'] == 'Lateral']['filename'].values[0])\n",
    "\n",
    "        # Load images\n",
    "        frontal_img = Image.open(frontal_img_path).convert(\"RGB\")\n",
    "        lateral_img = Image.open(lateral_img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            frontal_img = self.transform(frontal_img)\n",
    "            lateral_img = self.transform(lateral_img)\n",
    "\n",
    "        return frontal_img, lateral_img\n",
    "\n",
    "# Define transforms for image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = XRayDataset(csv_file=CSV_FILE, img_folder=IMAGE_FOLDER, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "class Generator3D(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator3D, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # First set of convolutional layers\n",
    "        self.conv1 = nn.ConvTranspose3d(latent_dim, 1024, 4, 1, 0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(1024)\n",
    "        \n",
    "        self.conv2 = nn.ConvTranspose3d(1024, 512, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(512)\n",
    "        \n",
    "        self.conv3 = nn.ConvTranspose3d(512, 256, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(256)\n",
    "        \n",
    "        # Additional complexity by adding more layers\n",
    "        self.conv4 = nn.ConvTranspose3d(256, 128, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.conv5 = nn.ConvTranspose3d(128, 64, 4, 2, 1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm3d(64)\n",
    "\n",
    "        self.conv6 = nn.ConvTranspose3d(64, 32, 4, 2, 1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm3d(32)\n",
    "        \n",
    "        self.conv7 = nn.ConvTranspose3d(32, 16, 4, 2, 1, bias=False)\n",
    "        self.bn7 = nn.BatchNorm3d(16)\n",
    "\n",
    "        # Final layer to produce the output\n",
    "        self.conv8 = nn.ConvTranspose3d(16, 1, 4, 2, 1, bias=False)\n",
    "\n",
    "        # Dropout layers for regularization\n",
    "        self.dropout = nn.Dropout3d(p=0.3)\n",
    "\n",
    "    def forward(self, z, frontal_img, lateral_img):\n",
    "        # z is the latent vector\n",
    "        \n",
    "        # Reshape z to match the first convolutional layer\n",
    "        x = z.view(-1, self.latent_dim, 1, 1, 1)\n",
    "        \n",
    "        # Pass through the layers with activations and batch normalization\n",
    "        x = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        x = nn.ReLU()(self.bn2(self.conv2(x)))\n",
    "        x = nn.ReLU()(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # More layers with increased complexity\n",
    "        x = nn.ReLU()(self.bn4(self.conv4(x)))\n",
    "        x = nn.ReLU()(self.bn5(self.conv5(x)))\n",
    "        x = nn.ReLU()(self.bn6(self.conv6(x)))\n",
    "        x = nn.ReLU()(self.bn7(self.conv7(x)))\n",
    "        \n",
    "        # Final convolution to get the output\n",
    "        x = torch.tanh(self.conv8(x))\n",
    "        \n",
    "        # Apply dropout (if needed for regularization)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Ensure the output size is 64x64x64\n",
    "        x = nn.functional.interpolate(x, size=(64, 64, 64), mode='trilinear', align_corners=False)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# --- 3D Discriminator ---\n",
    "class Discriminator3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator3D, self).__init__()\n",
    "\n",
    "        # Adjusted layers to handle the 3D inputs, including volume and images\n",
    "        self.conv1 = nn.Conv3d(7, 64, 4, 2, 1, bias=False)  # Volume + 2D images (frontal, lateral)\n",
    "        self.conv2 = nn.Conv3d(64, 128, 4, 2, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(128, 256, 4, 2, 1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm3d(256)\n",
    "        \n",
    "        self.conv4 = nn.Conv3d(256, 512, 4, 2, 1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm3d(512)\n",
    "\n",
    "        self.conv5 = nn.Conv3d(512, 1, 4, 1, 0, bias=False)\n",
    "    \n",
    "    def forward(self, volume, frontal_img, lateral_img):\n",
    "        # Adjust 2D images to match 3D volume dimensions (expand to 3D)\n",
    "        frontal_3d = frontal_img.unsqueeze(2).expand(-1, -1, volume.size(2), -1, -1)\n",
    "        lateral_3d = lateral_img.unsqueeze(3).expand(-1, -1, -1, volume.size(3), -1)\n",
    "        \n",
    "        # Ensure all tensors have the same size: 64x64x64\n",
    "        volume = nn.functional.interpolate(volume, size=(64, 64, 64), mode='trilinear', align_corners=False)\n",
    "        frontal_3d = nn.functional.interpolate(frontal_3d, size=(64, 64, 64), mode='trilinear', align_corners=False)\n",
    "        lateral_3d = nn.functional.interpolate(lateral_3d, size=(64, 64, 64), mode='trilinear', align_corners=False)\n",
    "        \n",
    "        # Concatenate volume and image features along the channel dimension (axis=1)\n",
    "        x = torch.cat([volume, frontal_3d, lateral_3d], dim=1)\n",
    "        \n",
    "        # Apply convolutional layers with LeakyReLU activations and BatchNorm\n",
    "        x = nn.LeakyReLU(0.2)(self.conv1(x))\n",
    "        x = nn.LeakyReLU(0.2)(self.bn2(self.conv2(x)))\n",
    "        x = nn.LeakyReLU(0.2)(self.bn3(self.conv3(x)))\n",
    "        x = nn.LeakyReLU(0.2)(self.bn4(self.conv4(x)))\n",
    "        \n",
    "        # Final sigmoid layer to output probability\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "        \n",
    "        return x.view(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize models and move them to the GPU\n",
    "generator = Generator3D(latent_dim=LATENT_DIM).to(device)\n",
    "discriminator = Discriminator3D().to(device)\n",
    "\n",
    "# Use DataParallel for multi-GPU setup\n",
    "# generator = nn.DataParallel(generator)\n",
    "# discriminator = nn.DataParallel(discriminator)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # Initialize progress bar\n",
    "    with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "        for i, (frontal_img, lateral_img) in enumerate(tepoch):\n",
    "            # Move images to GPU\n",
    "            frontal_img, lateral_img = frontal_img.to(device), lateral_img.to(device)\n",
    "\n",
    "            # Prepare real and fake labels\n",
    "            real_label = torch.ones(frontal_img.size(0), 1).to(device)\n",
    "            fake_label = torch.zeros(frontal_img.size(0), 1).to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            optimizer_d.zero_grad()\n",
    "\n",
    "            # Generate fake 3D volume\n",
    "            z = torch.randn(frontal_img.size(0), LATENT_DIM).to(device)\n",
    "            fake_volume = generator(z, frontal_img, lateral_img)\n",
    "\n",
    "            # Real images (using fake_volume as placeholder for real 3D volume)\n",
    "            real_pred = discriminator(fake_volume.detach(), frontal_img, lateral_img)\n",
    "            d_real_loss = adversarial_loss(real_pred, real_label)\n",
    "\n",
    "            # Fake images\n",
    "            fake_pred = discriminator(fake_volume.detach(), frontal_img, lateral_img)\n",
    "            d_fake_loss = adversarial_loss(fake_pred, fake_label)\n",
    "\n",
    "            d_loss = d_real_loss + d_fake_loss\n",
    "            d_loss.backward()\n",
    "            optimizer_d.step()\n",
    "            d_real_losses.append(d_real_loss.item())\n",
    "            d_fake_losses.append(d_fake_loss.item())\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_g.zero_grad()\n",
    "            fake_pred = discriminator(fake_volume, frontal_img, lateral_img)\n",
    "            g_loss = adversarial_loss(fake_pred, real_label)\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "            g_losses.append(g_loss.item())\n",
    "            tepoch.set_postfix(D_loss=d_loss.item(),D_Real_Loss = d_real_loss.item(),D_Fake_Loss = d_fake_loss.item(), G_loss=g_loss.item())\n",
    "\n",
    "print(\"Training finished.\")\n",
    "torch.save(generator.state_dict(), f\"generator3DMRCMPLX_{BATCH_SIZE}_{IMAGE_SIZE}_epoch_{EPOCHS}.pth\")\n",
    "torch.save(discriminator.state_dict(), f\"discriminator3DMRCMPLX_{BATCH_SIZE}_{IMAGE_SIZE}_epoch_{EPOCHS}.pth\")\n",
    "\n",
    "print(f\"Models saved at epoch {EPOCHS} with batch size {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(d_real_losses, label='Discriminator Real Loss', color='r')\n",
    "plt.plot(d_fake_losses, label='Discriminator Fake Loss', color='orange')\n",
    "plt.plot(g_losses, label='Generator Loss', color='b')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curves during Training')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'combined_losses_epoch_{EPOCHS}_batch_{BATCH_SIZE}_image_{IMAGE_SIZE}_CMPLX.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
