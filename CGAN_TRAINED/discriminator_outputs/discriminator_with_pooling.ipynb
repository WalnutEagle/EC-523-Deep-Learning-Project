{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603e11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 212/212 [12:38<00:00,  3.58s/batch, D_Fake_Loss=0.674, D_Real_Loss=0.714, d_loss=1.39, g_loss=0.726]\n",
      "  0%|          | 0/212 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Generator Loss: 222.0677, Discriminator Loss: 294.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 212/212 [12:03<00:00,  3.41s/batch, D_Fake_Loss=0.701, D_Real_Loss=0.684, d_loss=1.38, g_loss=1.17] \n",
      "  0%|          | 0/212 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Generator Loss: 213.1370, Discriminator Loss: 294.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  48%|████▊     | 101/212 [05:49<06:24,  3.46s/batch, D_Fake_Loss=0.673, D_Real_Loss=0.713, d_loss=1.39, g_loss=0.887]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset Class\n",
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_folder, transform=None):\n",
    "        self.csv = pd.read_csv(csv_file)\n",
    "        self.img_folder = img_folder\n",
    "        self.transform = transform\n",
    "        self.pairs = self.csv.groupby('uid')  \n",
    "        self.valid_uids = self.check_integrity()\n",
    "\n",
    "    def check_integrity(self):\n",
    "        valid_uids = []\n",
    "        for uid, group in self.pairs:\n",
    "            frontal_data = group[group['projection'] == 'Frontal']\n",
    "            lateral_data = group[group['projection'] == 'Lateral']\n",
    "            if frontal_data.empty or lateral_data.empty:\n",
    "                continue\n",
    "            valid_uids.append(uid)\n",
    "        return valid_uids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_uids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        group_key = self.valid_uids[idx]\n",
    "        uid = self.pairs.get_group(group_key)\n",
    "\n",
    "        frontal_img_path = os.path.join(self.img_folder, uid[uid['projection'] == 'Frontal']['filename'].values[0])\n",
    "        lateral_img_path = os.path.join(self.img_folder, uid[uid['projection'] == 'Lateral']['filename'].values[0])\n",
    "        frontal_img = Image.open(frontal_img_path).convert(\"RGB\")\n",
    "        lateral_img = Image.open(lateral_img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            frontal_img = self.transform(frontal_img)\n",
    "            lateral_img = self.transform(lateral_img)\n",
    "\n",
    "        return frontal_img, lateral_img\n",
    "\n",
    "# Define the Dense Block\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channels + i * growth_rate, growth_rate, kernel_size=3, padding=1),\n",
    "                nn.InstanceNorm2d(growth_rate),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            new_features = layer(x)\n",
    "            x = torch.cat([x, new_features], dim=1)\n",
    "        return x\n",
    "\n",
    "# Define the Basic3D Block\n",
    "class Basic3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Basic3D, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "# Define 2D to 3D Connection (Connection-C)\n",
    "class Connection2Dto3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Connection2Dto3D, self).__init__()\n",
    "        self.conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv3d = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x)\n",
    "        x = x.unsqueeze(2)\n",
    "        x = self.conv3d(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Updated Discriminator to be self-adjusting\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, base_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(\n",
    "            nn.Sequential(\n",
    "                nn.Conv3d(in_channels, base_channels, kernel_size=2, stride=2, padding=1),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Add subsequent convolutional layers\n",
    "        num_layers = 4  # Number of convolutional layers\n",
    "        for i in range(1, num_layers):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv3d(base_channels * (2 ** (i - 1)), base_channels * (2 ** i), kernel_size=2, stride=2, padding=1),\n",
    "                    nn.InstanceNorm3d(base_channels * (2 ** i)),\n",
    "                    nn.LeakyReLU(0.2, inplace=True)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Final layer\n",
    "        self.final_layer = nn.Conv3d(base_channels * (2 ** (num_layers - 1)), 1, kernel_size=2, stride=1, padding=0)\n",
    "        self.pooling = nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Ensure final output is flattened\n",
    "        x = self.final_layer(x)\n",
    "        x = self.pooling(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "# Updated Generator to verify and propagate image size\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, num_dense_layers, out_channels, image_size):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.num_upconv_layers = int(torch.log2(torch.tensor(image_size // 4)).item())\n",
    "\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n",
    "            DenseBlock(growth_rate, growth_rate, num_dense_layers),\n",
    "            nn.Conv2d(growth_rate * (num_dense_layers + 1), growth_rate, kernel_size=3, stride=2, padding=1)  # Compression\n",
    "        )\n",
    "\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1),\n",
    "            DenseBlock(growth_rate, growth_rate, num_dense_layers),\n",
    "            nn.Conv2d(growth_rate * (num_dense_layers + 1), growth_rate, kernel_size=3, stride=2, padding=1)  # Compression\n",
    "        )\n",
    "\n",
    "        self.connection_a = Connection2Dto3D(growth_rate, growth_rate)\n",
    "        self.connection_b = nn.Conv3d(growth_rate * 2, growth_rate, kernel_size=3, padding=1)\n",
    "        self.connection_c = nn.Conv3d(growth_rate, growth_rate, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv_layers = nn.ModuleList()\n",
    "        for _ in range(self.num_upconv_layers):\n",
    "            self.upconv_layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose3d(growth_rate, growth_rate, kernel_size=4, stride=2, padding=1),\n",
    "                    nn.InstanceNorm3d(growth_rate),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.final_layer = nn.Conv3d(growth_rate, out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        x1 = self.encoder1(x1)\n",
    "        x2 = self.encoder2(x2)\n",
    "        x1 = self.connection_a(x1)\n",
    "        x2 = self.connection_a(x2)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.connection_b(x)\n",
    "        for upconv in self.upconv_layers:\n",
    "            x = upconv(x)\n",
    "\n",
    "        x = self.final_layer(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Paths and Hyperparameters\n",
    "    IMAGE_FOLDER = '/projectnb/ec523kb/projects/teams_Fall_2024/Team_11/Adwait/Work_on_this_code/images/images_normalized/'\n",
    "    CSV_FILE = '/projectnb/ec523kb/projects/teams_Fall_2024/Team_11/Adwait/Work_on_this_code/indiana_projections.csv'\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 10\n",
    "    IMAGE_SIZE = 100\n",
    "    LATENT_DIM = 100\n",
    "    IN_CHANNELS = 3\n",
    "    OUT_CHANNELS = 1\n",
    "    GROWTH_RATE = 16\n",
    "    NUM_DENSE_LAYERS = 4\n",
    "    BASE_CHANNELS = 64\n",
    "\n",
    "    d_real_losses = []\n",
    "    d_fake_losses = []\n",
    "    g_losses = []\n",
    "\n",
    "    # Dataset and Dataloader\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = XRayDataset(CSV_FILE, IMAGE_FOLDER, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # Initialize Generator and Discriminator\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generator = Generator(\n",
    "        in_channels=IN_CHANNELS,\n",
    "        growth_rate=GROWTH_RATE,\n",
    "        num_dense_layers=NUM_DENSE_LAYERS,\n",
    "        out_channels=OUT_CHANNELS,\n",
    "        image_size=IMAGE_SIZE\n",
    "    ).to(device)\n",
    "    generator = nn.DataParallel(generator)\n",
    "\n",
    "    discriminator = Discriminator(OUT_CHANNELS, BASE_CHANNELS).to(device)\n",
    "    discriminator = nn.DataParallel(discriminator)\n",
    "\n",
    "    g_optim = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    d_optim = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "    g_criterion = nn.MSELoss()\n",
    "    d_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "        g_epoch_loss = 0\n",
    "        d_epoch_loss = 0\n",
    "\n",
    "        with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "            for frontal_img, lateral_img in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "                frontal_img = frontal_img.to(device)\n",
    "                lateral_img = lateral_img.to(device)\n",
    "                real_labels = torch.ones((frontal_img.size(0),), device=device)\n",
    "                fake_labels = torch.zeros((frontal_img.size(0),), device=device)\n",
    "                # ===================== Train Discriminator =====================\n",
    "                # Generate fake samples\n",
    "                fake_volumes = generator(frontal_img, lateral_img)\n",
    "\n",
    "                # Real samples\n",
    "                real_outputs = discriminator(fake_volumes.detach())\n",
    "                real_loss = d_criterion(real_outputs, real_labels)\n",
    "\n",
    "                # Fake samples\n",
    "                fake_outputs = discriminator(fake_volumes.detach())\n",
    "                fake_loss = d_criterion(fake_outputs, fake_labels)\n",
    "\n",
    "                # Backpropagation for Discriminator\n",
    "                d_loss = real_loss + fake_loss\n",
    "                d_optim.zero_grad()\n",
    "                d_loss.backward()\n",
    "                d_optim.step()\n",
    "                d_real_losses.append(real_loss.item())\n",
    "                d_fake_losses.append(fake_loss.item())\n",
    "                d_epoch_loss += d_loss.item()\n",
    "\n",
    "                # ===================== Train Generator =====================\n",
    "                fake_outputs = discriminator(fake_volumes)\n",
    "                g_loss = g_criterion(fake_outputs, real_labels)\n",
    "\n",
    "                g_optim.zero_grad()\n",
    "                g_loss.backward()\n",
    "                g_optim.step()\n",
    "\n",
    "                g_epoch_loss += g_loss.item()\n",
    "                g_losses.append(g_loss.item())\n",
    "\n",
    "                # Ground truths\n",
    "\n",
    "\n",
    "                tepoch.set_postfix(d_loss=d_loss.item(), g_loss=g_loss.item(),D_Real_Loss = real_loss.item(), D_Fake_Loss = fake_loss.item())\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "    # Save Models\n",
    "    torch.save(generator.state_dict(), f\"generator_{BATCH_SIZE}_{IMAGE_SIZE}_epoch_{EPOCHS}.pth\")\n",
    "    torch.save(discriminator.state_dict(), f\"discriminator_{BATCH_SIZE}_{IMAGE_SIZE}_epoch_{EPOCHS}.pth\")\n",
    "\n",
    "    print(f\"Models saved at epoch {EPOCHS} with batch size {BATCH_SIZE} and image size {IMAGE_SIZE}\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(d_real_losses, label='Discriminator Real Loss', color='r')\n",
    "    plt.plot(d_fake_losses, label='Discriminator Fake Loss', color='orange')\n",
    "    plt.plot(g_losses, label='Generator Loss', color='b')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curves during Training')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'losses_epoch_{EPOCHS}_batch_{BATCH_SIZE}_image_{IMAGE_SIZE}_3DGANDiscriminator.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AROUND 12 Minutes per epoch so take 15 mins for each epoch while submitting a batch job :)\n",
    "#ALSO this config takes nearly 70gb vram so its like A100 or 2 L40S."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
